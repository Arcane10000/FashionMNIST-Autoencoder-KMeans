{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "401c862a",
   "metadata": {},
   "source": [
    "### Step 1: Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a014242",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision datasets transformers scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf5f01f",
   "metadata": {},
   "source": [
    "### Step 2: Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff459c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, accuracy_score\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4627182a",
   "metadata": {},
   "source": [
    "### Step 3: Load Fashion MNIST Dataset from HuggingFace Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44c4ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {'train': 'fashion_mnist/train-00000-of-00001.parquet',\n",
    "          'test': 'fashion_mnist/test-00000-of-00001.parquet'}\n",
    "\n",
    "df = pd.read_parquet(\"hf://datasets/zalando-datasets/fashion_mnist/\" + splits[\"train\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49e9b55",
   "metadata": {},
   "source": [
    "### Step 4: Convert Image Bytes to NumPy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bdb4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "def decode_image(example):\n",
    "    return np.array(Image.open(io.BytesIO(example['bytes'])))\n",
    "\n",
    "X = np.stack([decode_image(row) for row in df['image']])\n",
    "X = X.reshape(len(X), -1).astype(\"float32\") / 255.0  # Normalize to (0, 1)\n",
    "y = df['label'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5410de2",
   "metadata": {},
   "source": [
    "### Step 5: Define Autoencoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafeeb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(784, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 784),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        out = self.decoder(z)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd41acce",
   "metadata": {},
   "source": [
    "### Step 6: Train Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92618e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Autoencoder().to(device)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(torch.tensor(X)), batch_size=128, shuffle=True)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(20):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        x_batch = batch[0].to(device).float()\n",
    "        output = model(x_batch)\n",
    "        loss = criterion(output, x_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/20, Loss: {total_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4cc85b",
   "metadata": {},
   "source": [
    "### Step 7: Encode Data for Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ac197b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    compressed = model.encoder(torch.tensor(X).to(device).float()).cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95248482",
   "metadata": {},
   "source": [
    "### Step 8: KMeans Clustering + Silhouette Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5164cf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=10, random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(compressed)\n",
    "print(\"Silhouette Score:\", silhouette_score(compressed, cluster_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e5af49",
   "metadata": {},
   "source": [
    "### Step 9: Purity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234ebd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def purity_score(y_true, y_pred):\n",
    "    labels = np.zeros_like(y_pred)\n",
    "    for i in range(10):\n",
    "        mask = (y_pred == i)\n",
    "        if np.any(mask):\n",
    "            labels[mask] = mode(y_true[mask])[0]\n",
    "    return accuracy_score(y_true, labels)\n",
    "\n",
    "purity = purity_score(y, cluster_labels)\n",
    "print(f\"Purity Score: {purity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5c5e76",
   "metadata": {},
   "source": [
    "### Step 10: Visualize Clusters using t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cc3606",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "tsne_result = tsne.fit_transform(compressed)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(tsne_result[:, 0], tsne_result[:, 1], c=cluster_labels, cmap='tab10', s=10)\n",
    "plt.title(\"t-SNE Clustering of Encoded Data\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9467f538",
   "metadata": {},
   "source": [
    "### Step 11: Adjusted Rand Index (ARI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683acd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_rand_score\n",
    "ari = adjusted_rand_score(y, cluster_labels)\n",
    "print(f\"Adjusted Rand Index: {ari:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca97f7b",
   "metadata": {},
   "source": [
    "### Step 12: Normalized Mutual Information (NMI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d440d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "nmi = normalized_mutual_info_score(y, cluster_labels)\n",
    "print(f\"Normalized Mutual Information: {nmi:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7f0935",
   "metadata": {},
   "source": [
    "### Step 13: Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc7ea22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mapped_labels = np.zeros_like(cluster_labels)\n",
    "for i in range(10):\n",
    "    mask = (cluster_labels == i)\n",
    "    if np.any(mask):\n",
    "        mapped_labels[mask] = mode(y[mask])[0]\n",
    "\n",
    "conf_mat = confusion_matrix(y, mapped_labels)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_mat, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=range(10), yticklabels=range(10))\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
